{
  "suite": "quick",
  "models": [
    "codeparrot-small"
  ],
  "start_time": "2025-09-09T09:57:57.271938",
  "benchmarks": [
    {
      "name": "humaneval",
      "results": [
        {
          "model": "codeparrot-small",
          "benchmark": "humaneval",
          "start_time": "2025-09-09T09:57:57.271953",
          "end_time": "2025-09-09T10:01:24.160642",
          "duration_seconds": 206.88868856430054,
          "success": true,
          "stdout": "Selected Tasks: ['humaneval']\nLoading model in fp16\nnumber of problems for this task is 10\ngenerations were saved at /home/cordlesssteve/projects/ai-benchmark-suite/results/generations_1757429877_humaneval.json\nEvaluating generations...\n{\n  \"humaneval\": {\n    \"pass@1\": 0.0\n  },\n  \"config\": {\n    \"prefix\": \"\",\n    \"do_sample\": true,\n    \"temperature\": 0.2,\n    \"top_k\": 0,\n    \"top_p\": 0.95,\n    \"n_samples\": 1,\n    \"eos\": \"<|endoftext|>\",\n    \"seed\": 0,\n    \"model\": \"codeparrot/codeparrot-small\",\n    \"modeltype\": \"causal\",\n    \"peft_model\": null,\n    \"revision\": null,\n    \"use_auth_token\": false,\n    \"trust_remote_code\": false,\n    \"tasks\": \"humaneval\",\n    \"instruction_tokens\": null,\n    \"batch_size\": 1,\n    \"max_length_generation\": 512,\n    \"precision\": \"fp16\",\n    \"load_in_8bit\": false,\n    \"load_in_4bit\": false,\n    \"left_padding\": false,\n    \"limit\": 10,\n    \"limit_start\": 0,\n    \"save_every_k_tasks\": -1,\n    \"postprocess\": true,\n    \"allow_code_execution\": true,\n    \"generation_only\": false,\n    \"load_generations_path\": null,\n    \"load_data_path\": null,\n    \"metric_output_path\": \"/home/cordlesssteve/projects/ai-benchmark-suite/results/metrics_1757429877.json\",\n    \"save_generations\": true,\n    \"load_generations_intermediate_paths\": null,\n    \"save_generations_path\": \"/home/cordlesssteve/projects/ai-benchmark-suite/results/generations_1757429877.json\",\n    \"save_references\": false,\n    \"save_references_path\": \"references.json\",\n    \"prompt\": \"prompt\",\n    \"max_memory_per_gpu\": null,\n    \"check_references\": false\n  }\n}\n",
          "stderr": "\n  0%|          | 0/10 [00:00<?, ?it/s]\n 10%|\u2588         | 1/10 [00:18<02:43, 18.11s/it]\n 20%|\u2588\u2588        | 2/10 [00:39<02:39, 19.93s/it]\n 30%|\u2588\u2588\u2588       | 3/10 [00:53<02:00, 17.24s/it]\n 40%|\u2588\u2588\u2588\u2588      | 4/10 [01:14<01:53, 18.97s/it]\n 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [01:29<01:27, 17.52s/it]\n 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [01:55<01:21, 20.34s/it]\n 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [02:14<00:59, 19.67s/it]\n 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [02:32<00:38, 19.33s/it]\n 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [02:55<00:20, 20.33s/it]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [03:08<00:00, 18.19s/it]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [03:08<00:00, 18.85s/it]\n",
          "command": "/home/cordlesssteve/projects/ai-benchmark-suite/bigcode-evaluation-harness/venv/bin/python main.py --model codeparrot/codeparrot-small --tasks humaneval --temperature 0.2 --save_generations --metric_output_path /home/cordlesssteve/projects/ai-benchmark-suite/results/metrics_1757429877.json --save_generations_path /home/cordlesssteve/projects/ai-benchmark-suite/results/generations_1757429877.json --precision fp16 --batch_size 1 --allow_code_execution --limit 10 --n_samples 1"
        }
      ]
    }
  ],
  "end_time": "2025-09-09T10:01:24.160860",
  "duration_seconds": 206.88892245292664
}